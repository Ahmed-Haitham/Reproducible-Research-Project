{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import utils.extract_df as extract_df\n",
    "import utils.transform as transform\n",
    "import utils.clustering as clustering\n",
    "import utils.feature_engineering as feature_engineering\n",
    "import utils.model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # extract taxi_data.csv\n",
    "    filepathcsv = \"data/taxi_data.csv\"\n",
    "    df = extract_df.readcsv(filepathcsv)\n",
    "\n",
    "    # extract nyc.shp\n",
    "    filepathshp =\"data/nyc-boundaries/geo_export_9ca5396d-336c-47af-9742-ab30cd995e41.shp\"\n",
    "    nyc = extract_df.readshp(filepathshp)\n",
    "\n",
    "    # transform & data cleaning\n",
    "    transformer = transform.dataTransformation(df,nyc)\n",
    "    transformedDf = transformer.transform()\n",
    "\n",
    "    # feature engineering\n",
    "    filepathtemp = \"data/NYC_Weather_2014_2020.csv\"\n",
    "    temperature_df = extract_df.readcsv(filepathtemp)\n",
    "    merged_df = feature_engineering.add_temperature(transformedDf, temperature_df)\n",
    "\n",
    "    # clustering\n",
    "    cluster = clustering.pickUpCluster(merged_df)\n",
    "    df = cluster.clusterCreated()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../model/clean_data/clustered_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop datetime column\n",
    "df_modelling = df.drop(columns=['pickup_datetime','date'], inplace=False)\n",
    "# model filepahts\n",
    "model_RF_path = \"data/models/RF_model.pkl\"\n",
    "model_RF_log_path = \"data/models/RF_model_log.pkl\"\n",
    "# define models\n",
    "RF = model.Model(model_RF_path, df_modelling, 'fare_amount')\n",
    "RF_log = model.Model(model_RF_log_path, df_modelling, 'fare_amount_log')\n",
    "# fit models\n",
    "RF.load_model()\n",
    "RF.prepare_data()\n",
    "RF.fit_model()\n",
    "RF_log.load_model()\n",
    "RF_log.prepare_data()\n",
    "RF_log.fit_model()\n",
    "# predict\n",
    "# TODO just for prints\n",
    "print(RF.predict(RF.X_test))\n",
    "print(RF_log.predict(RF_log.X_test))\n",
    "# train score\n",
    "print(RF.train_score())\n",
    "print(RF_log.train_score())\n",
    "# test score\n",
    "print(RF.test_score())\n",
    "print(RF_log.test_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "df_modelling = df.drop(columns=['pickup_datetime','date'], inplace=False)\n",
    "# One hot encode passenger_big_group, pickup_cluster\n",
    "df_modelling = pd.get_dummies(df_modelling, columns=['passenger_big_group','pickup_cluster'])\n",
    "# model filepahts\n",
    "model_XGB_path = \"data/models/XGB_model.pkl\"\n",
    "# XGB = joblib.load(model_XGB_path)\n",
    "# XGB.fit()\n",
    "# define models\n",
    "XGB = model.Model(model_XGB_path, df_modelling, 'fare_amount')\n",
    "# fit models\n",
    "XGB.load_model()\n",
    "XGB.prepare_data()\n",
    "XGB = XGB.fit_model()\n",
    "explainer = shap.Explainer(XGB)\n",
    "print(df_modelling.drop(['fare_amount','fare_amount_log'],axis=1).columns)\n",
    "# display(df_modelling.drop(['fare_amount'],axis=1).iloc[:26452500])\n",
    "shap_values = explainer(df_modelling.drop(['fare_amount', 'fare_amount_log'],axis=1))\n",
    "# visualize the first prediction's explanation with a force plot\n",
    "shap.plots.force(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"data/models/shap_values_XGB.pkl\", \"wb\") as output_file:\n",
    "     pickle.dump(shap_values, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"data/models/shap_values_XGB.pkl\", \"rb\") as input_file:\n",
    "    shap_values_pkl = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.plots.initjs()\n",
    "shap.plots.force(shap_values_pkl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values_pkl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#         'n_estimators': [100, 200],\n",
    "#         'max_features': [1.0, 'sqrt', 'log2'],\n",
    "#         'max_depth' : [4,8],\n",
    "#         'min_samples_split': [2],\n",
    "#     }\n",
    "param_grid = {\n",
    "    'n_estimators': [1000], #Irena 1000\n",
    "    'max_features': [1.0,'sqrt'], #Irena tuned this one\n",
    "    'max_depth' : [8],\n",
    "    'min_samples_split': [2,4,8], #Irena tuned this one\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! streamlit run 1_Homepage.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
